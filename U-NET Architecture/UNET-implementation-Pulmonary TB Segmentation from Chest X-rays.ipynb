{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UNET-implementation-Pulmonary TB Segmentation from Chest X-rays.ipynb","provenance":[],"authorship_tag":"ABX9TyP4GKBcoUyEMFscUVkQx0D2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Snx2fpxJt40p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"620d1d59-9435-49f5-e54a-c3e69fcfca57","executionInfo":{"status":"ok","timestamp":1585230427463,"user_tz":-300,"elapsed":41676,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tlB6XsRCF8lL","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras import backend as keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import Callback\n","from keras.callbacks import ModelCheckpoint, CSVLogger\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TW4aXbHwG0uA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"375ae420-b9fb-46d6-e1f8-50897379e070","executionInfo":{"status":"ok","timestamp":1585235855064,"user_tz":-300,"elapsed":4271,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["os.chdir('/content/drive/My Drive/GitHub Repositories/State of Art Segmentation Network Architectures')\n","\n","images = np.load('./datasets/Pulmonary TB Segmentation from Chest X-rays Dataset/images.npy')\n","# Z-score Normalization\n","mean = np.mean(images)\n","std = np.std(images)\n","images -= mean\n","images /= std\n","\n","masks = np.load('./datasets/Pulmonary TB Segmentation from Chest X-rays Dataset/masks.npy')\n","# Normalize masks to [0, 1]\n","masks /= 255. \n","\n","print('Images: {} | Dtype: {} | Max-Val: {} | Min-Val: {}'.format(images.shape, images.dtype, np.amax(images), np.amin(images)))\n","print('Masks: {} | Dtype: {} | Max-Val: {} | Min-Val: {}'.format(masks.shape, masks.dtype, np.amax(masks), np.amin(masks)))\n","\n","print('Images: {} | Dtype: {} | Max-Val: {} | Min-Val: {}'.format(images.shape, images.dtype, np.amax(images), np.amin(images)))\n","print('Masks: {} | Dtype: {} | Max-Val: {} | Min-Val: {}'.format(masks.shape, masks.dtype, np.amax(masks), np.amin(masks)))\n","\n","images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.05, random_state=2020)\n","print('Train Images: {} | Train Masks: {}'.format(images_train.shape, masks_train.shape))\n","print('Validation Images: {} | Validation Masks: {}'.format(images_test.shape, masks_test.shape))\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Images: (336, 512, 512, 1) | Dtype: float32 | Max-Val: 1.4261432886123657 | Min-Val: -1.8582361936569214\n","Masks: (336, 512, 512, 1) | Dtype: float32 | Max-Val: 1.0 | Min-Val: 0.0\n","Images: (336, 512, 512, 1) | Dtype: float32 | Max-Val: 1.4261432886123657 | Min-Val: -1.8582361936569214\n","Masks: (336, 512, 512, 1) | Dtype: float32 | Max-Val: 1.0 | Min-Val: 0.0\n","Train Images: (319, 512, 512, 1) | Train Masks: (319, 512, 512, 1)\n","Validation Images: (17, 512, 512, 1) | Validation Masks: (17, 512, 512, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wWrUzm7WPiBU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d39dfa8b-746e-4ab5-f0b0-01b62059ec9e","executionInfo":{"status":"ok","timestamp":1585236662348,"user_tz":-300,"elapsed":1859,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["IMG_SIZE = 512\n","smooth = 1\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","def precision(y_true, y_pred):\n","    \"\"\" Precision metric. Only computes a batch-wise average of precision. Computes the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\"\"\"\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def recall(y_true, y_pred):\n","    \"\"\" Recall metric. Only computes a batch-wise average of recall. Computes the recall, a metric for multi-label classification of\n","    how many relevant items are selected. \"\"\"\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def f1score(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\" Recall metric. Only computes a batch-wise average of recall. Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected. \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric. Only computes a batch-wise average of precision. Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant. \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    f1score =  2 * ((precision * recall) / (precision + recall))\n","    return f1score\n","\n","\n","def dataGenerator(images, masks, batchsize):\n","  imagesGenerator = ImageDataGenerator(horizontal_flip = True, width_shift_range=0.1, height_shift_range=0.1,\n","                                  rotation_range=10, zoom_range=0.1).flow(images, images, batchsize, seed=2020)\n","  \n","  masksGenerator = ImageDataGenerator(horizontal_flip = True, vertical_flip=True, width_shift_range=0.1, height_shift_range=0.1,\n","                                 rotation_range=10, zoom_range=0.1).flow(masks, masks, batchsize, seed=2020)\n","  while True:\n","    x_batch, _ = imagesGenerator.next()\n","    y_batch, _ = masksGenerator.next()\n","    yield x_batch, y_batch\n","\n","def UNET_Architecture():\n","    inputs = Input((IMG_SIZE, IMG_SIZE, 1))\n","    \n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n","\n","    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n","    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","\n","    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n","    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","\n","    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n","    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","\n","    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n","    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","    \n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","    return Model(inputs=[inputs], outputs=[conv10])\n","\n","model = UNET_Architecture()\n","model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef, 'accuracy', precision, recall, f1score])\n","model.summary()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Model: \"model_8\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            (None, 512, 512, 1)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_138 (Conv2D)             (None, 512, 512, 32) 320         input_8[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_139 (Conv2D)             (None, 512, 512, 32) 9248        conv2d_138[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_31 (MaxPooling2D) (None, 256, 256, 32) 0           conv2d_139[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_140 (Conv2D)             (None, 256, 256, 64) 18496       max_pooling2d_31[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_141 (Conv2D)             (None, 256, 256, 64) 36928       conv2d_140[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_32 (MaxPooling2D) (None, 128, 128, 64) 0           conv2d_141[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_142 (Conv2D)             (None, 128, 128, 128 73856       max_pooling2d_32[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_143 (Conv2D)             (None, 128, 128, 128 147584      conv2d_142[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_33 (MaxPooling2D) (None, 64, 64, 128)  0           conv2d_143[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_144 (Conv2D)             (None, 64, 64, 256)  295168      max_pooling2d_33[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_145 (Conv2D)             (None, 64, 64, 256)  590080      conv2d_144[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_34 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_145[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_146 (Conv2D)             (None, 32, 32, 512)  1180160     max_pooling2d_34[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_147 (Conv2D)             (None, 32, 32, 512)  2359808     conv2d_146[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_29 (Conv2DTran (None, 64, 64, 256)  524544      conv2d_147[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 64, 64, 512)  0           conv2d_transpose_29[0][0]        \n","                                                                 conv2d_145[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_148 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_149 (Conv2D)             (None, 64, 64, 256)  590080      conv2d_148[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_30 (Conv2DTran (None, 128, 128, 128 131200      conv2d_149[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 128, 128, 256 0           conv2d_transpose_30[0][0]        \n","                                                                 conv2d_143[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_150 (Conv2D)             (None, 128, 128, 128 295040      concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_151 (Conv2D)             (None, 128, 128, 128 147584      conv2d_150[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_31 (Conv2DTran (None, 256, 256, 64) 32832       conv2d_151[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 256, 256, 128 0           conv2d_transpose_31[0][0]        \n","                                                                 conv2d_141[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_152 (Conv2D)             (None, 256, 256, 64) 73792       concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_153 (Conv2D)             (None, 256, 256, 64) 36928       conv2d_152[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_32 (Conv2DTran (None, 512, 512, 32) 8224        conv2d_153[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 512, 512, 64) 0           conv2d_transpose_32[0][0]        \n","                                                                 conv2d_139[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_154 (Conv2D)             (None, 512, 512, 32) 18464       concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_155 (Conv2D)             (None, 512, 512, 32) 9248        conv2d_154[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_156 (Conv2D)             (None, 512, 512, 1)  33          conv2d_155[0][0]                 \n","==================================================================================================\n","Total params: 7,759,521\n","Trainable params: 7,759,521\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aeOo-BICQaiB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"outputId":"1b184caa-5884-43e9-b175-19864d43b3da","executionInfo":{"status":"error","timestamp":1585236992725,"user_tz":-300,"elapsed":15917,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ1mFA3pQtq_kbc72-pLy5yrV90Q5vLSpZX076=s64","userId":"05353617243036990298"}}},"source":["import math\n","class prediction_history(Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if (epoch+1) % 10 == 1:\n","      print('Prediction Results at epoch: {} are below'.format(epoch+1))\n","      self.pred = model.predict(images_test)\n","      plot_images(images_test, self.pred, masks_test)\n","        \n","def plot_images(images_test, pred, masks_test):\n","  plt.figure(1, figsize = (12, 12))\n","  for i in range(5):\n","    plt.subplot(1, 5, i+1).set_title('TestImage# {}' .format(i+1))\n","    plt.imshow(images_test[i, :, :, 0], cmap='gray')\n","  plt.figure(2, figsize = (12, 12))\n","  for i in range(5):\n","    plt.subplot(1, 5, i+1).set_title('Prediction# {}' .format(i+1))\n","    plt.imshow(pred[i, :, :, 0], cmap='gray')\n","  plt.figure(3, figsize = (12, 12))\n","  for i in range(5):\n","    plt.subplot(1, 5, i+1).set_title('Ground-Truth# {}' .format(i+1))\n","    plt.imshow(masks_test[i, :, :, 0], cmap='gray')\n","  plt.show()\n","  plt.close()\n","\n","predictions = prediction_history()\n","checkpoint = ModelCheckpoint('./saved Models/UNET Models/Pulmonary TB Segmentation from Chest X-rays/best-model.h5', verbose=1, monitor='val_acc',\n","                             save_best_only=True, mode='auto') \n","batchsize = 16\n","epochs = 150\n","model.fit_generator(dataGenerator(images, masks, batchsize), steps_per_epoch = math.ceil(images_train.shape[0]/batchsize),\n","                    validation_data = (images_test, masks_test), epochs=epochs, verbose=1, callbacks = [checkpoint, predictions])"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-037df6e8dc9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m model.fit_generator(dataGenerator(images, masks, batchsize), steps_per_epoch = math.ceil(images_train.shape[0]/batchsize),\n\u001b[0;32m---> 31\u001b[0;31m                     validation_data = (images_test, masks_test), epochs=epochs, verbose=1, callbacks = [checkpoint, predictions])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,32,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/Adam/gradients/conv2d_156/convolution_grad/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"]}]},{"cell_type":"code","metadata":{"id":"gf8DnlC1cFVz","colab_type":"code","colab":{}},"source":["def plot_images(images_test, pred, masks_test):\n","  plt.figure(1, figsize = (20, 20))\n","  for i in range(7):\n","    plt.subplot(1, 7, i+1).set_title('Image# {}' .format(i+1))\n","    plt.imshow(images_test[i, :, :, 0], cmap='gray')\n","    plt.axis('off')\n","  plt.figure(2, figsize = (20, 20))\n","  for i in range(7):\n","    plt.subplot(1, 7, i+1).set_title('Prediction# {}' .format(i+1))\n","    plt.imshow(pred[i, :, :, 0], cmap='gray')\n","    plt.axis('off')\n","\n","  plt.figure(3, figsize = (20, 20))\n","  for i in range(7):\n","    plt.subplot(1, 7, i+1).set_title('Ground-Truth# {}' .format(i+1))\n","    plt.imshow(masks_test[i, :, :, 0], cmap='gray')\n","    plt.axis('off')\n","\n","  plt.show()\n","  plt.close()\n","\n","pred = model.predict(images_test)\n","plot_images(images_test, pred, masks_test)"],"execution_count":0,"outputs":[]}]}